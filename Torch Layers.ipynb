{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebe3f250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display full output\n",
    "from IPython.core.interactiveshell import InteractiveShell \n",
    "InteractiveShell.ast_node_interactivity = 'all' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c2f42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108c51fb",
   "metadata": {},
   "source": [
    "# torch.nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33b7d088",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(10,4) # size (10,4) in neural networks mean there're 10 learning examples in the inputs, each with 4 features\n",
    "fc = nn.Linear(in_features= 4, out_features = 1) # in_features should be equal to inputs.shape[1], the out_features is the number of features of the target\n",
    "outputs = fc(inputs) # hence, the outputs would in the size of (10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8681ddc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3102,  0.1271, -0.0823,  1.0858],\n",
       "        [-1.1686,  1.6650,  1.3797, -0.9915],\n",
       "        [ 0.3897,  0.3723,  1.0115,  0.1784],\n",
       "        [ 1.9373, -1.0086,  0.7447,  0.2432],\n",
       "        [ 0.4305,  0.0627,  0.7668, -1.9446],\n",
       "        [ 1.0522, -0.2573,  0.6940,  0.0913],\n",
       "        [-0.0278, -0.0746, -0.0560, -1.1732],\n",
       "        [-1.1034,  0.8108, -1.1170, -0.2516],\n",
       "        [-1.1515,  1.2772, -1.6101, -0.8164],\n",
       "        [-0.6352,  0.9345,  0.4916,  1.1171]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2397],\n",
       "        [-0.9325],\n",
       "        [-0.7593],\n",
       "        [-0.8897],\n",
       "        [-1.2447],\n",
       "        [-0.7963],\n",
       "        [-0.7541],\n",
       "        [-0.1225],\n",
       "        [-0.1838],\n",
       "        [-0.2319]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs\n",
    "outputs\n",
    "\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e9aba6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2009, -0.0747, -0.2266,  0.2618]], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.4708], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the weights and biases in this 'fc' linear layer\n",
    "fc.weight\n",
    "fc.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d23b0f",
   "metadata": {},
   "source": [
    "The algorithm behind the linear layer is actually some basic matrix calculus:\n",
    "$$outputs = inputs \\times weight_T + bias$$\n",
    "Let's manually implement it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2c1a59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2397],\n",
       "        [-0.9325],\n",
       "        [-0.7593],\n",
       "        [-0.8897],\n",
       "        [-1.2447],\n",
       "        [-0.7963],\n",
       "        [-0.7541],\n",
       "        [-0.1225],\n",
       "        [-0.1838],\n",
       "        [-0.2319]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(inputs,fc.weight.T).add(fc.bias) # Here we get the same outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7115f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4864],\n",
       "        [ 1.7685],\n",
       "        [ 0.5358],\n",
       "        [-0.1849],\n",
       "        [ 1.2545],\n",
       "        [ 0.1672],\n",
       "        [ 0.4731],\n",
       "        [-0.0845],\n",
       "        [ 0.1134],\n",
       "        [ 0.1043]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4864],\n",
       "        [ 1.7685],\n",
       "        [ 0.5358],\n",
       "        [-0.1849],\n",
       "        [ 1.2545],\n",
       "        [ 0.1672],\n",
       "        [ 0.4731],\n",
       "        [-0.0845],\n",
       "        [ 0.1134],\n",
       "        [ 0.1043]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1 = nn.Linear(in_features=4, out_features=1, bias=False) # We could remove the bias by setting it to False\n",
    "fc1(inputs)\n",
    "torch.mm(inputs,fc1.weight.T) # Again we get the same outputs as fc1(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d879a204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a4ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ffef57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b13f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aa1917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
